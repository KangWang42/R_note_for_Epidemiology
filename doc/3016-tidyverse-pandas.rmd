---
title: 'tidyverse vs pandas: R与Python数据处理对比'
date: '2026-01-25'
categories:
- 实用操作
- 数据导入导出
- tidyverse
image: images/tidyverse-pandas-cover.svg
description: 系统对比tidyverse和pandas的数据处理语法,帮助你在两种语言间无缝切换
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    warning = FALSE,
    message = FALSE,
    fig.width = 8,
    fig.height = 5,
    fig.retina = 2,
    out.width = "100%",
    dpi = 150
)
```

## 框架简介

**tidyverse** 和 **pandas** 分别是 R 和 Python 中最流行的数据处理框架,掌握两者的对应关系能帮助你在不同语言间快速切换。

### 核心对比

| 维度 | tidyverse (R) | pandas (Python) |
|------|---------------|-----------------|
| **核心包** | dplyr, tidyr, readr, ggplot2 | pandas, matplotlib, seaborn |
| **数据结构** | tibble (data.frame) | DataFrame |
| **索引方式** | 基于列名 | 基于位置/标签 |
| **链式语法** | `%>%` (magrittr) 或 `|>` (native) | `.` 方法链 |
| **缺失值** | `NA` | `NaN`, `None` |
| **生态系统** | 统计、建模、可视化 | 机器学习、科学计算 |
| **性能** | 中等 (dplyr) / 快 (data.table) | 快 (NumPy后端) |

### 为什么需要对比学习?

- **跨语言协作**: 团队可能混用R和Python
- **工具选择**: 根据任务特点选择最合适的工具
- **知识迁移**: 一种语言的经验能快速迁移到另一种

## 安装与加载

### R (tidyverse)

```{r install-r, eval=FALSE}
# 安装tidyverse套件
install.packages("tidyverse")

# 或单独安装核心包
install.packages(c("dplyr", "tidyr", "readr", "ggplot2"))
```

```{r load-r}
library(tidyverse)

# 示例数据
data(mtcars)
df_r <- as_tibble(mtcars, rownames = "car")
head(df_r, 3)
```

### Python (pandas)

```{python eval=FALSE, install-py, eval=FALSE}
# 安装pandas
pip install pandas matplotlib seaborn

# 或使用conda
conda install pandas matplotlib seaborn
```

```{python eval=FALSE, load-py, eval=FALSE}
import pandas as pd
import numpy as np

# 示例数据
import seaborn as sns
df_py = sns.load_dataset('mpg')
df_py.head(3)
```

## 数据读取与写入

### 读取CSV文件

**tidyverse (R)**
```{r read-csv-r, eval=FALSE}
# 使用readr包
df <- read_csv("data.csv")

# 常用参数
df <- read_csv(
  "data.csv",
  col_types = cols(        # 指定列类型
    id = col_integer(),
    name = col_character(),
    date = col_date()
  ),
  na = c("", "NA", "NULL"), # 缺失值标识
  skip = 1                  # 跳过行数
)
```

**pandas (Python)**
```{python eval=FALSE, read-csv-py, eval=FALSE}
# 使用pandas
df = pd.read_csv('data.csv')

# 常用参数
df = pd.read_csv(
    'data.csv',
    dtype={                 # 指定列类型
        'id': int,
        'name': str,
        'date': str
    },
    na_values=['', 'NA', 'NULL'],  # 缺失值标识
    skiprows=1,            # 跳过行数
    parse_dates=['date']   # 解析日期列
)
```

### 写入CSV文件

**tidyverse (R)**
```{r write-csv-r, eval=FALSE}
# 写入CSV
write_csv(df, "output.csv")

# 保留行名
write_csv(df, "output.csv", row.names = TRUE)
```

**pandas (Python)**
```{python eval=FALSE, write-csv-py, eval=FALSE}
# 写入CSV
df.to_csv('output.csv', index=False)

# 保留索引
df.to_csv('output.csv', index=True)
```

### 读取Excel文件

**tidyverse (R)**
```{r read-excel-r, eval=FALSE}
library(readxl)

# 读取Excel
df <- read_excel("data.xlsx", sheet = "Sheet1")
```

**pandas (Python)**
```{python eval=FALSE, read-excel-py, eval=FALSE}
# 读取Excel
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')
```

## 数据筛选

### 筛选行 (filter / query)

**tidyverse (R)**
```{r filter-r}
# 单条件筛选
df_r %>% filter(mpg > 25)

# 多条件筛选 (AND)
df_r %>% filter(mpg > 20, cyl == 4)

# 多条件筛选 (OR)
df_r %>% filter(mpg > 30 | hp > 200)

# 使用 %in%
df_r %>% filter(cyl %in% c(4, 6))
```

**pandas (Python)**
```{python eval=FALSE, filter-py}
# 单条件筛选
df_py[df_py['mpg'] > 25]

# 多条件筛选 (AND)
df_py[(df_py['mpg'] > 20) & (df_py['cylinders'] == 4)]

# 多条件筛选 (OR)
df_py[(df_py['mpg'] > 30) | (df_py['horsepower'] > 200)]

# 使用 isin()
df_py[df_py['cylinders'].isin([4, 6])]

# 或使用 query() 方法 (推荐)
df_py.query('mpg > 25')
df_py.query('mpg > 20 and cylinders == 4')
```

### 选择列 (select / filter)

**tidyverse (R)**
```{r select-r}
# 选择特定列
df_r %>% select(car, mpg, hp)

# 排除列
df_r %>% select(-vs, -am)

# 选择范围
df_r %>% select(mpg:hp)

# 辅助函数
df_r %>% select(starts_with("c"))     # 以c开头
df_r %>% select(ends_with("p"))       # 以p结尾
df_r %>% select(contains("ar"))       # 包含ar
df_r %>% select(where(is.numeric))    # 数值型列
```

**pandas (Python)**
```{python eval=FALSE, select-py}
# 选择特定列
df_py[['name', 'mpg', 'horsepower']]

# 或使用 filter()
df_py.filter(items=['name', 'mpg', 'horsepower'])

# 排除列
df_py.drop(columns=['origin', 'year'])

# 选择范围 (需要知道列的位置)
df_py.iloc[:, 0:3]

# 正则匹配列名
df_py.filter(regex='^c')              # 以c开头
df_py.filter(regex='p$')              # 以p结尾
df_py.filter(like='ar')               # 包含ar

# 选择数值型列
df_py.select_dtypes(include=['number'])
```

## 数据排序

### 排序 (arrange / sort_values)

**tidyverse (R)**
```{r arrange-r}
# 升序排序
df_r %>% arrange(mpg)

# 降序排序
df_r %>% arrange(desc(mpg))

# 多列排序
df_r %>% arrange(cyl, desc(mpg))
```

**pandas (Python)**
```{python eval=FALSE, arrange-py}
# 升序排序
df_py.sort_values('mpg')

# 降序排序
df_py.sort_values('mpg', ascending=False)

# 多列排序
df_py.sort_values(['cylinders', 'mpg'], ascending=[True, False])
```

## 数据转换

### 创建/修改列 (mutate / assign)

**tidyverse (R)**
```{r mutate-r}
# 创建新列
df_r %>% 
  mutate(
    kpl = mpg * 0.425,          # 英里转公里
    hp_per_cyl = hp / cyl,      # 每缸马力
    efficiency = ifelse(mpg > 20, "high", "low")
  )

# 修改现有列
df_r %>% 
  mutate(
    mpg = round(mpg, 1),
    hp = as.integer(hp)
  )
```

**pandas (Python)**
```{python eval=FALSE, mutate-py}
# 创建新列
df_py_new = df_py.assign(
    kpl = df_py['mpg'] * 0.425,
    hp_per_cyl = df_py['horsepower'] / df_py['cylinders'],
    efficiency = lambda x: x['mpg'].apply(lambda y: 'high' if y > 20 else 'low')
)

# 或直接赋值 (会修改原数据)
df_py['kpl'] = df_py['mpg'] * 0.425
df_py['hp_per_cyl'] = df_py['horsepower'] / df_py['cylinders']

# 修改现有列
df_py['mpg'] = df_py['mpg'].round(1)
df_py['horsepower'] = df_py['horsepower'].astype(int)
```

### 重命名列 (rename)

**tidyverse (R)**
```{r rename-r}
# 重命名列
df_r %>% 
  rename(
    miles_per_gallon = mpg,
    horsepower = hp
  )
```

**pandas (Python)**
```{python eval=FALSE, rename-py}
# 重命名列
df_py.rename(columns={
    'mpg': 'miles_per_gallon',
    'horsepower': 'horse_power'
})
```

## 分组聚合

### 分组汇总 (group_by + summarise / groupby + agg)

**tidyverse (R)**
```{r groupby-r}
# 分组汇总
df_r %>% 
  group_by(cyl) %>% 
  summarise(
    n = n(),                    # 计数
    mean_mpg = mean(mpg),       # 均值
    sd_mpg = sd(mpg),           # 标准差
    median_hp = median(hp)      # 中位数
  )

# 多列分组
df_r %>% 
  group_by(cyl, gear) %>% 
  summarise(
    avg_mpg = mean(mpg),
    .groups = "drop"            # 取消分组
  )
```

**pandas (Python)**
```{python eval=FALSE, groupby-py}
# 分组汇总
df_py.groupby('cylinders').agg({
    'mpg': ['count', 'mean', 'std'],
    'horsepower': 'median'
}).reset_index()

# 或使用多个聚合函数
df_py.groupby('cylinders')['mpg'].agg([
    ('n', 'count'),
    ('mean_mpg', 'mean'),
    ('sd_mpg', 'std')
]).reset_index()

# 多列分组
df_py.groupby(['cylinders', 'model_year'])['mpg'].mean().reset_index()
```

### 分组转换 (mutate / transform)

**tidyverse (R)**
```{r group-mutate-r}
# 分组后创建新列
df_r %>% 
  group_by(cyl) %>% 
  mutate(
    mean_mpg = mean(mpg),       # 组内均值
    mpg_diff = mpg - mean_mpg   # 偏差
  ) %>% 
  ungroup()
```

**pandas (Python)**
```{python eval=FALSE, group-mutate-py}
# 分组后创建新列
df_py['mean_mpg'] = df_py.groupby('cylinders')['mpg'].transform('mean')
df_py['mpg_diff'] = df_py['mpg'] - df_py['mean_mpg']
```

## 数据合并

### 横向合并 (left_join / merge)

**tidyverse (R)**
```{r join-r}
# 创建示例数据
df1_r <- tibble(
  id = 1:3,
  name = c("Alice", "Bob", "Charlie")
)

df2_r <- tibble(
  id = 2:4,
  score = c(85, 90, 95)
)

# 左连接
left_join(df1_r, df2_r, by = "id")

# 右连接
right_join(df1_r, df2_r, by = "id")

# 内连接
inner_join(df1_r, df2_r, by = "id")

# 全连接
full_join(df1_r, df2_r, by = "id")
```

**pandas (Python)**
```{python eval=FALSE, join-py}
# 创建示例数据
df1_py = pd.DataFrame({
    'id': [1, 2, 3],
    'name': ['Alice', 'Bob', 'Charlie']
})

df2_py = pd.DataFrame({
    'id': [2, 3, 4],
    'score': [85, 90, 95]
})

# 左连接
pd.merge(df1_py, df2_py, on='id', how='left')

# 右连接
pd.merge(df1_py, df2_py, on='id', how='right')

# 内连接
pd.merge(df1_py, df2_py, on='id', how='inner')

# 全连接
pd.merge(df1_py, df2_py, on='id', how='outer')
```

### 纵向合并 (bind_rows / concat)

**tidyverse (R)**
```{r bind-r}
# 纵向拼接
df_a <- tibble(x = 1:3, y = c("a", "b", "c"))
df_b <- tibble(x = 4:6, y = c("d", "e", "f"))

bind_rows(df_a, df_b)
```

**pandas (Python)**
```{python eval=FALSE, bind-py}
# 纵向拼接
df_a_py = pd.DataFrame({'x': [1, 2, 3], 'y': ['a', 'b', 'c']})
df_b_py = pd.DataFrame({'x': [4, 5, 6], 'y': ['d', 'e', 'f']})

pd.concat([df_a_py, df_b_py], ignore_index=True)
```

## 数据重塑

### 长宽转换 (pivot_longer / melt, pivot_wider / pivot)

**tidyverse (R)**
```{r reshape-r}
# 宽转长
wide_r <- tibble(
  id = 1:3,
  y2020 = c(10, 20, 30),
  y2021 = c(15, 25, 35)
)

long_r <- wide_r %>% 
  pivot_longer(
    cols = starts_with("y"),
    names_to = "year",
    values_to = "value"
  )

long_r

# 长转宽
long_r %>% 
  pivot_wider(
    names_from = year,
    values_from = value
  )
```

**pandas (Python)**
```{python eval=FALSE, reshape-py}
# 宽转长
wide_py = pd.DataFrame({
    'id': [1, 2, 3],
    'y2020': [10, 20, 30],
    'y2021': [15, 25, 35]
})

long_py = wide_py.melt(
    id_vars='id',
    value_vars=['y2020', 'y2021'],
    var_name='year',
    value_name='value'
)

long_py

# 长转宽
long_py.pivot(
    index='id',
    columns='year',
    values='value'
).reset_index()
```

## 缺失值处理

### 检测缺失值

**tidyverse (R)**
```{r na-detect-r}
# 创建含缺失值的数据
df_na_r <- tibble(
  x = c(1, 2, NA, 4),
  y = c("a", NA, "c", "d")
)

# 检测缺失值
df_na_r %>% 
  summarise(
    x_na = sum(is.na(x)),
    y_na = sum(is.na(y))
  )

# 筛选含缺失值的行
df_na_r %>% filter(is.na(x))

# 删除含缺失值的行
df_na_r %>% drop_na()
```

**pandas (Python)**
```{python eval=FALSE, na-detect-py}
# 创建含缺失值的数据
df_na_py = pd.DataFrame({
    'x': [1, 2, np.nan, 4],
    'y': ['a', None, 'c', 'd']
})

# 检测缺失值
df_na_py.isnull().sum()

# 筛选含缺失值的行
df_na_py[df_na_py['x'].isnull()]

# 删除含缺失值的行
df_na_py.dropna()
```

### 填充缺失值

**tidyverse (R)**
```{r na-fill-r}
# 用固定值填充
df_na_r %>% 
  mutate(
    x = replace_na(x, 0),
    y = replace_na(y, "missing")
  )

# 用前一个值填充
df_na_r %>% 
  fill(x, .direction = "down")
```

**pandas (Python)**
```{python eval=FALSE, na-fill-py}
# 用固定值填充
df_na_py.fillna({'x': 0, 'y': 'missing'})

# 用前一个值填充
df_na_py.fillna(method='ffill')  # 或 df_na_py.ffill()
```

## 字符串操作

### 字符串处理

**tidyverse (R)**
```{r string-r}
df_str_r <- tibble(
  text = c("apple", "banana", "cherry")
)

# 转大写
df_str_r %>% mutate(upper = str_to_upper(text))

# 提取子串
df_str_r %>% mutate(first_3 = str_sub(text, 1, 3))

# 检测模式
df_str_r %>% filter(str_detect(text, "an"))

# 替换
df_str_r %>% mutate(replaced = str_replace(text, "a", "X"))
```

**pandas (Python)**
```{python eval=FALSE, string-py}
df_str_py = pd.DataFrame({
    'text': ['apple', 'banana', 'cherry']
})

# 转大写
df_str_py['upper'] = df_str_py['text'].str.upper()

# 提取子串
df_str_py['first_3'] = df_str_py['text'].str[:3]

# 检测模式
df_str_py[df_str_py['text'].str.contains('an')]

# 替换
df_str_py['replaced'] = df_str_py['text'].str.replace('a', 'X')
```

## 日期时间处理

### 日期操作

**tidyverse (R)**
```{r date-r}
library(lubridate)

df_date_r <- tibble(
  date_str = c("2024-01-15", "2024-02-20", "2024-03-25")
)

# 解析日期
df_date_r %>% 
  mutate(
    date = ymd(date_str),         # 解析
    year = year(ymd(date_str)),   # 提取年
    month = month(ymd(date_str)), # 提取月
    day = day(ymd(date_str))      # 提取日
  )
```

**pandas (Python)**
```{python eval=FALSE, date-py}
df_date_py = pd.DataFrame({
    'date_str': ['2024-01-15', '2024-02-20', '2024-03-25']
})

# 解析日期
df_date_py['date'] = pd.to_datetime(df_date_py['date_str'])
df_date_py['year'] = df_date_py['date'].dt.year
df_date_py['month'] = df_date_py['date'].dt.month
df_date_py['day'] = df_date_py['date'].dt.day
```

## 高级操作

### 窗口函数

**tidyverse (R)**
```{r window-r}
df_r %>% 
  arrange(mpg) %>% 
  mutate(
    row_num = row_number(),       # 行号
    rank = min_rank(mpg),         # 排名
    lag_mpg = lag(mpg),           # 前一行
    lead_mpg = lead(mpg),         # 后一行
    cumsum_mpg = cumsum(mpg)      # 累计和
  )
```

**pandas (Python)**
```{python eval=FALSE, window-py}
df_py_sorted = df_py.sort_values('mpg').reset_index(drop=True)

df_py_sorted['row_num'] = range(len(df_py_sorted))
df_py_sorted['rank'] = df_py_sorted['mpg'].rank(method='min')
df_py_sorted['lag_mpg'] = df_py_sorted['mpg'].shift(1)
df_py_sorted['lead_mpg'] = df_py_sorted['mpg'].shift(-1)
df_py_sorted['cumsum_mpg'] = df_py_sorted['mpg'].cumsum()
```

### 条件汇总

**tidyverse (R)**
```{r case-r}
df_r %>% 
  mutate(
    category = case_when(
      mpg > 25 ~ "high",
      mpg > 15 ~ "medium",
      TRUE ~ "low"
    )
  )
```

**pandas (Python)**
```{python eval=FALSE, case-py}
import numpy as np

df_py['category'] = np.select(
    [df_py['mpg'] > 25, df_py['mpg'] > 15],
    ['high', 'medium'],
    default='low'
)
```

## 链式操作对比

### 完整数据处理流程

**tidyverse (R)**
```{r pipeline-r}
# 链式操作
result_r <- df_r %>% 
  filter(cyl %in% c(4, 6, 8)) %>%     # 筛选
  select(car, mpg, cyl, hp) %>%        # 选择列
  mutate(
    efficiency = mpg / hp,             # 创建新列
    category = ifelse(mpg > 20, "高效", "低效")
  ) %>% 
  group_by(cyl, category) %>%          # 分组
  summarise(
    n = n(),
    avg_mpg = mean(mpg),
    .groups = "drop"
  ) %>% 
  arrange(desc(avg_mpg))               # 排序

result_r
```

**pandas (Python)**
```{python eval=FALSE, pipeline-py}
# 方法链
result_py = (
    df_py
    .query('cylinders in [4, 6, 8]')           # 筛选
    .filter(items=['name', 'mpg', 'cylinders', 'horsepower'])  # 选择列
    .assign(
        efficiency = lambda x: x['mpg'] / x['horsepower'],
        category = lambda x: x['mpg'].apply(lambda y: '高效' if y > 20 else '低效')
    )
    .groupby(['cylinders', 'category'])        # 分组
    .agg(
        n = ('mpg', 'count'),
        avg_mpg = ('mpg', 'mean')
    )
    .reset_index()
    .sort_values('avg_mpg', ascending=False)   # 排序
)

result_py
```

## 性能对比

### 大数据处理

**tidyverse (R)**
```{r perf-r, eval=FALSE}
library(microbenchmark)

# 生成测试数据
n <- 1e6
test_df <- tibble(
  x = rnorm(n),
  y = sample(letters, n, replace = TRUE)
)

# 性能测试
microbenchmark(
  tidyverse = test_df %>% 
    filter(x > 0) %>% 
    group_by(y) %>% 
    summarise(mean_x = mean(x)),
  times = 10
)
```

**pandas (Python)**
```{python eval=FALSE, perf-py, eval=FALSE}
import timeit

# 生成测试数据
n = 1000000
test_df_py = pd.DataFrame({
    'x': np.random.randn(n),
    'y': np.random.choice(list('abcdefghijklmnopqrstuvwxyz'), n)
})

# 性能测试
def test_pandas():
    return (test_df_py
            .query('x > 0')
            .groupby('y')['x']
            .mean())

timeit.timeit(test_pandas, number=10)
```

### 性能优化建议

| 操作类型 | tidyverse 优化 | pandas 优化 |
|---------|---------------|-------------|
| **大数据** | 使用 `data.table` 或 `dtplyr` | 使用 `query()` 代替布尔索引 |
| **分组聚合** | `summarise()` 使用向量化函数 | 使用 `agg()` 而非 `apply()` |
| **循环** | 使用 `purrr::map()` | 使用向量化操作或 `apply()` |
| **内存** | `gc()` 手动回收 | `del` 删除不用的变量 |

## 生态系统对比

### 可视化

**tidyverse (R) - ggplot2**
```{r viz-r, fig.height=4}
library(ggplot2)

df_r %>% 
  ggplot(aes(x = wt, y = mpg, color = factor(cyl))) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "油耗 vs 重量",
    x = "重量 (1000 lbs)",
    y = "油耗 (mpg)",
    color = "气缸数"
  ) +
  theme_minimal()
```

**pandas (Python) - matplotlib/seaborn**
```{python eval=FALSE, viz-py, eval=FALSE}
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 5))
sns.scatterplot(data=df_py, x='weight', y='mpg', hue='cylinders', s=100)
sns.regplot(data=df_py, x='weight', y='mpg', scatter=False)
plt.title('油耗 vs 重量')
plt.xlabel('重量 (lbs)')
plt.ylabel('油耗 (mpg)')
plt.legend(title='气缸数')
plt.tight_layout()
plt.show()
```

### 统计建模

**tidyverse (R)**
```{r model-r}
library(broom)

# 线性回归
model_r <- lm(mpg ~ wt + hp, data = df_r)

# 整理结果
tidy(model_r)
glance(model_r)
```

**pandas (Python)**
```{python eval=FALSE, model-py, eval=FALSE}
from sklearn.linear_model import LinearRegression
import statsmodels.api as sm

# 线性回归
X = df_py[['weight', 'horsepower']].dropna()
y = df_py.loc[X.index, 'mpg']

model_py = sm.OLS(y, sm.add_constant(X)).fit()
print(model_py.summary())
```

## 常见陷阱

### 索引差异

**tidyverse (R)**
```{r index-r}
# R的索引从1开始
df_r[1, ]      # 第一行
df_r[, 1]      # 第一列

# 负索引表示排除
df_r[-1, ]     # 排除第一行
```

**pandas (Python)**
```{python eval=FALSE, index-py}
# Python的索引从0开始
df_py.iloc[0]     # 第一行
df_py.iloc[:, 0]  # 第一列

# 负索引表示从后往前
df_py.iloc[-1]    # 最后一行
```

### 复制 vs 引用

**tidyverse (R)**
```{r copy-r}
# R默认复制
df_copy_r <- df_r
df_copy_r$new_col <- 1

# df_r 不受影响
"new_col" %in% names(df_r)
```

**pandas (Python)**
```{python eval=FALSE, copy-py}
# pandas默认引用
df_copy_py = df_py  # 这是引用!

# 需要显式复制
df_copy_py = df_py.copy()
df_copy_py['new_col'] = 1

# df_py 不受影响
'new_col' in df_py.columns
```

## 何时选择哪个?

### 使用 tidyverse (R) 的场景

- **统计分析**: R有更丰富的统计包
- **学术研究**: 最新统计方法通常先在R实现
- **可视化**: ggplot2的图形更精美
- **小到中等数据**: 1-10GB以内

### 使用 pandas (Python) 的场景

- **机器学习**: scikit-learn生态系统
- **深度学习**: TensorFlow, PyTorch
- **大数据**: Dask, PySpark
- **生产环境**: 更好的工程支持

## 最佳实践

### 代码风格

**tidyverse (R)**
```{r style-r, eval=FALSE}
# 推荐风格
df %>% 
  filter(condition) %>%      # 每行一个操作
  select(col1, col2) %>%     # 使用空格
  mutate(new_col = expr)     # 清晰的命名
```

**pandas (Python)**
```{python eval=FALSE, style-py, eval=FALSE}
# 推荐风格
(df
 .query('condition')         # 缩进对齐
 .filter(items=['col1', 'col2'])
 .assign(new_col=lambda x: x['expr']))  # lambda清晰表达依赖
```

### 调试技巧

**tidyverse (R)**
```{r debug-r, eval=FALSE}
# 检查中间结果
df %>% 
  filter(x > 0) %>% 
  {print(nrow(.)); .} %>%    # 打印行数
  mutate(y = x * 2)
```

**pandas (Python)**
```{python eval=FALSE, debug-py, eval=FALSE}
# 检查中间结果
(df
 .query('x > 0')
 .pipe(lambda x: print(len(x)) or x)  # 打印行数
 .assign(y=lambda x: x['x'] * 2))
```

## 相关资源

### tidyverse (R)

- **官方文档**: https://www.tidyverse.org/
- **R for Data Science**: https://r4ds.had.co.nz/
- **dplyr文档**: https://dplyr.tidyverse.org/
- **tidyr文档**: https://tidyr.tidyverse.org/

### pandas (Python)

- **官方文档**: https://pandas.pydata.org/
- **10分钟入门**: https://pandas.pydata.org/docs/user_guide/10min.html
- **API参考**: https://pandas.pydata.org/docs/reference/index.html

### 对照表

- **pandas to R**: https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html
- **R to pandas**: https://gist.github.com/conormm/fd8b1980c28dd21cfaf6975c86c74d07

## 总结

| 对比维度 | tidyverse | pandas |
|---------|-----------|--------|
| **学习曲线** | 陡峭(函数式编程) | 平缓(面向对象) |
| **语法风格** | 管道链式 | 方法链 |
| **适用场景** | 统计分析、学术研究 | 机器学习、工程应用 |
| **性能** | 中等 | 优秀 |
| **生态** | 统计建模 | 科学计算 |
| **社区** | 学术界主导 | 工业界主导 |

**关键建议**:
- 两种工具都值得掌握
- 根据项目需求选择合适的工具
- 利用已有经验快速迁移知识
- 混合使用时注意数据交换格式 (如通过CSV或Arrow)
