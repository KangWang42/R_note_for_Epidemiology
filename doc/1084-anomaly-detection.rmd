---
title: 无监督异常检测完整教程
subtitle: "Isolation Forest 与 LOF 的实战流程"
date: "2026-01-17"
image: images/1084-anomaly-detection-cover.svg
categories:
- 机器学习与AI
- 机器学习框架
- 无监督
- 异常检测
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 7.2,
  fig.height = 4.8,
  dpi = 150,
  out.width = "100%",
  fig.path = "figure/1084-anomaly-"
)
```

```{r packages}
library(dplyr)
library(ggplot2)
library(rsample)
library(yardstick)
library(isotree)
library(dbscan)
```

## 教程目标与适用场景

异常检测用于识别少数偏离正常模式的样本，常见于欺诈检测、异常监测。
本教程展示 Isolation Forest 与 LOF 的完整流程。

**适合场景**

- 标签稀缺或没有明确异常标签
- 异常比例较低且分布明显不同

**不适合场景**

- 异常与正常难以区分、噪声极高
- 需要明确可解释规则的场景

## 模型入门：从0理解异常检测

无监督异常检测的核心是“正常样本占多数，异常样本很少”。
模型不依赖标签，而是通过样本的稀疏性或密度差异发现异常。

- **Isolation Forest**：通过随机切分样本，异常点更容易被隔离，
  分割路径更短，得分更高。
- **LOF**（局部离群因子）：比较样本与邻居的密度，
  如果密度明显更低，就被视为异常。

实践中需要先估计异常比例，再用阈值把连续得分转成“异常/正常”。

## 方法框架与流程

异常检测的标准流程是：先估计异常比例与代价，再用无监督模型输出分数，
最后用阈值与验证集确定判定规则。对于时间序列或业务监测，
还需要定期重新训练或更新阈值以应对漂移。

### 关键概念与分数解释

- **异常得分**：越高表示越偏离正常模式，但阈值需要业务定义。
- **阈值选择**：常用分位数、验证集或成本敏感策略。
- **可用指标**：ROC AUC 反映区分度，召回率体现漏报风险。

### 评价指标选择

异常检测常常更关心召回率与精确率，而非单纯准确率。
因此应结合业务成本决定优先指标，再确定阈值。

## 数据准备与模拟异常

```{r data-prep}
set.seed(2026)
base_data <- mtcars |>
  select(mpg, disp, hp, wt)

anomalies <- base_data[1:5, ] |>
  mutate(
    mpg = mpg * 0.4,
    disp = disp * 2,
    hp = hp * 2.2,
    wt = wt * 1.8
  )

full_data <- bind_rows(
  base_data |> mutate(label = "normal"),
  anomalies |> mutate(label = "anomaly")
) |>
  mutate(label = factor(label, levels = c("anomaly", "normal")))

split_obj <- initial_split(full_data, prop = 0.8, strata = label)
train_data <- training(split_obj)
test_data <- testing(split_obj)
```

## 最小可运行示例：Isolation Forest

```{r iso-fit}
set.seed(2026)
iso_model <- isolation.forest(
  as.matrix(select(train_data, -label)),
  ntrees = 200,
  sample_size = 0.8
)

iso_scores <- predict(iso_model, as.matrix(select(test_data, -label)), type = "score")
```

```{r iso-eval}
threshold <- quantile(iso_scores, 0.95)
pred_label <- if_else(iso_scores >= threshold, "anomaly", "normal") |>
  factor(levels = levels(test_data$label))

iso_metrics <- tibble(
  truth = test_data$label,
  .pred_anomaly = iso_scores,
  .pred_class = pred_label
) |>
  summarise(
    accuracy = yardstick::accuracy_vec(truth, .pred_class),
    roc_auc = yardstick::roc_auc_vec(truth, .pred_anomaly, event_level = "first"),
    precision = yardstick::precision_vec(truth, .pred_class, event_level = "first"),
    recall = yardstick::recall_vec(truth, .pred_class, event_level = "first")
  )

iso_metrics
```

## 进阶示例：LOF 局部离群因子

```{r lof-fit}
lof_matrix <- as.matrix(select(test_data, -label))
min_pts <- max(2, min(10, nrow(lof_matrix) - 1))
lof_scores <- lof(lof_matrix, minPts = min_pts)
lof_threshold <- quantile(lof_scores, 0.95)
lof_pred <- if_else(lof_scores >= lof_threshold, "anomaly", "normal") |>
  factor(levels = levels(test_data$label))

lof_metrics <- tibble(
  truth = test_data$label,
  .pred_anomaly = lof_scores,
  .pred_class = lof_pred
) |>
  summarise(
    accuracy = yardstick::accuracy_vec(truth, .pred_class),
    roc_auc = yardstick::roc_auc_vec(truth, .pred_anomaly, event_level = "first"),
    precision = yardstick::precision_vec(truth, .pred_class, event_level = "first"),
    recall = yardstick::recall_vec(truth, .pred_class, event_level = "first")
  )

lof_metrics
```

## 可视化异常分布

```{r anomaly-plot}
plot_df <- test_data |>
  mutate(score = iso_scores, pred = pred_label)

ggplot(plot_df, aes(x = mpg, y = hp, color = pred)) +
  geom_point(size = 2, alpha = 0.85) +
  scale_color_manual(values = c("anomaly" = "#ef4444", "normal" = "#4f46e5")) +
  labs(title = "Isolation Forest 异常检测结果") +
  theme_minimal(base_size = 12)
```

## 常见错误与优化

- **阈值随意选择**：建议结合业务或验证集调节。
- **异常比例估计错误**：Isolation Forest 需合理 `sample_size`。
- **未做标准化**：在高尺度差异的变量上效果下降。
- **忽视时间漂移**：异常检测模型需要周期性更新。
- **仅依赖单模型**：可用规则或简单模型作为基线对照。

## 部署与复现建议

```{r anomaly-save}
model_path <- "models/isolation-forest.rds"
if (!dir.exists("models")) dir.create("models")
saveRDS(iso_model, model_path)

loaded_model <- readRDS(model_path)
all.equal(loaded_model$ntrees, iso_model$ntrees)
```

```{r anomaly-cleanup}
if (file.exists("models/isolation-forest.rds")) {
  file.remove("models/isolation-forest.rds")
}
if (dir.exists("models")) {
  unlink("models", recursive = TRUE)
}
```

## 总结

Isolation Forest 适合高维数据的异常识别，LOF 更强调局部密度差异。
结合业务阈值、周期性更新可以提升异常检测的稳定性。